setwd("E:/TrendMining/source_code/TrendMining")
#For example
query_string = "DevOps"#2208 items works for demo
my_filename = "devops_so"
my_articles = get_stackoverflow_data(query_string)
source("FunctionsStackOverflowApi.R")
#For example
query_string = "DevOps"#2208 items works for demo
my_filename = "devops_so"
my_articles = get_stackoverflow_data(query_string)
#** CLEAN YOUR ENVIRONMENT
#** You may want to clear your environment variables when starting a session. Saves from plenty of headache.
rm(list=ls())
#** Set your work directory to the TrendMining project directory (where the script file are)
#** A folder "data" will be created for saving files (if such folder does not exist)
#** EDIT THE FOLLOWING LINE, set your own work directory
#setwd("K:/My Documents/Projects/TrendMining_2017/TrendMining")
setwd("E:/TrendMining")
my_work_dir = getwd()
my_data_dir = "data"
if (!file.exists(my_data_dir)) {
dir.create(file.path(my_work_dir, my_data_dir))
}
#** STACKOVERFLOW API KEY
#** Set your own StackOverflow API key here (or use the default below)
#** EDIT THE FOLLOWING LINE for your own API key
#api_key = "9raZ36FkYGFHDSNrW)gdsw((" TODO old file name edit out
so_api_key = "Zt5gfc9eSaW68FsAKjHXhg(("
#** GETOLDTWEETS-JAVA PATH
#** Set path to the directory for "GetOldTweets-java-master"
getoldtweets_path = paste(getwd(),"/GetOldTweets-java-master", sep="")
#** SCOPUS API KEY
#** Set your own Scopus API key here
#** Create an account & create your API key => <your-own-scopus-api-key>
#** https://dev.elsevier.com/user/login
#** Replace the next line with set_api_key("YOUR_SCOPUS_KEY_HERE")
#** EDIT THE FOLLOWING LINE with YOUR OWN Scopus API key
#install.packages("rscopus", dependencies = TRUE)
library("rscopus")
set_api_key("5cd1321fa87640a65e146086a5cffa2b")
#alternatively you may store it a personal file somewhere else.
#alternatively you may store it a personal file somewhere else.
#source("C:/Users/mmantyla/Dropbox/Research - Publications/2017 Agile Book Chapter/Scripts/SetScopusApiKey.R")
source("FunctionsStackOverflowApi.R")
#For example
query_string = "DevOps"#2208 items works for demo
my_filename = "devops_so"
my_articles = get_stackoverflow_data(query_string)
source("FunctionsStackOverflowApi.R")
setwd("E:/TrendMining/source_code/TrendMining")
#** SCOPUS API KEY
#** Set your own Scopus API key here
#** Create an account & create your API key => <your-own-scopus-api-key>
#** https://dev.elsevier.com/user/login
#** Replace the next line with set_api_key("YOUR_SCOPUS_KEY_HERE")
#** EDIT THE FOLLOWING LINE with YOUR OWN Scopus API key
#install.packages("rscopus", dependencies = TRUE)
library("rscopus")
set_api_key("5cd1321fa87640a65e146086a5cffa2b")
#alternatively you may store it a personal file somewhere else.
#alternatively you may store it a personal file somewhere else.
#source("C:/Users/mmantyla/Dropbox/Research - Publications/2017 Agile Book Chapter/Scripts/SetScopusApiKey.R")
#alternatively you may store it a personal file somewhere else.
#source("C:/Users/mmantyla/Dropbox/Research - Publications/2017 Agile Book Chapter/Scripts/SetScopusApiKey.R")
#alternatively you may store it a personal file somewhere else.
#source("C:/Users/mmantyla/Dropbox/Research - Publications/2017 Agile Book Chapter/Scripts/SetScopusApiKey.R")
source("FunctionsStackOverflowApi.R")
#For example
query_string = "DevOps"#2208 items works for demo
my_filename = "devops_so"
my_articles = get_stackoverflow_data(query_string)
#For example
query_string = "[devops]"#2208 items works for demo
my_filename = "devops_so"
my_articles = get_stackoverflow_data(query_string)
View(my_articles)
#remove source code and othe stuff from the body of the asnwer. It is called abstract to make it compatible with Scopus data
abstract = my_articles$Abstract
abstract = gsub("<code.*/code>", "", abstract)
abstract = gsub("<code.*<truncated>", "", abstract)
abstract = gsub("<.*?>", "", abstract)
abstract = gsub("//.*\n", " ", abstract)
abstract = gsub("\\{\n.*\\}\n", " ", abstract)
abstract = gsub("[\r\n]", " ", abstract)
abstract = gsub("\"", "", abstract)
abstract = gsub("[0-9]", "", abstract)
#Add cleaned abstracts as a new column.
#We could also replace the existing but debugging is easier if we keep both.
my_articles$Abstract_clean = tolower(abstract)
my_articles$Title = tolower(my_articles$Title)
#Date is character covert to Date object
my_articles$Date = as.Date(my_articles$Date)
my_articles$CR_Date = as.Date(my_articles$CR_Date)
my_articles$LA_Date = as.Date(my_articles$LA_Date)
#Fixed filename: data/my_STO_<xxx>_data.RData
my_file = my_work_dir
my_file = paste(my_file, "/data/my_STO_", sep="", collapse=" ")
my_file = paste(my_file, my_filename, sep="", collapse=" ")
my_file = paste(my_file, "_data.RData", sep="", collapse=" ")
save(my_articles, file=my_file)
return(my_file)
#install.packages("rJava", dependencies = TRUE)
library(rJava)
source("FunctionsTwitterApi.R")
#For example
query_string = "#DevOps"
my_filename = "devops"
#This may take quite a long time, depending on the data
#You may test duration like this. Then compute how long it would take to get max tweets
#system.time(my_articles <- get_twitter_data(query_string, maxtweets=100))
#system.time(my_articles <- get_twitter_data(query_string, maxtweets=200))
my_articles <- get_twitter_data(query_string, maxtweets=6000)
#** CLEAN YOUR ENVIRONMENT
#** You may want to clear your environment variables when starting a session. Saves from plenty of headache.
rm(list=ls())
#** Set your work directory to the TrendMining project directory (where the script file are)
#** A folder "data" will be created for saving files (if such folder does not exist)
#** EDIT THE FOLLOWING LINE, set your own work directory
#setwd("K:/My Documents/Projects/TrendMining_2017/TrendMining")
setwd("E:/TrendMining/source_code/TrendMining")
my_work_dir = getwd()
my_data_dir = "data"
if (!file.exists(my_data_dir)) {
dir.create(file.path(my_work_dir, my_data_dir))
}
#** STACKOVERFLOW API KEY
#** Set your own StackOverflow API key here (or use the default below)
#** EDIT THE FOLLOWING LINE for your own API key
#api_key = "9raZ36FkYGFHDSNrW)gdsw((" TODO old file name edit out
so_api_key = "Zt5gfc9eSaW68FsAKjHXhg(("
#** GETOLDTWEETS-JAVA PATH
#** Set path to the directory for "GetOldTweets-java-master"
getoldtweets_path = paste(getwd(),"/GetOldTweets-java-master", sep="")
#** SCOPUS API KEY
#** Set your own Scopus API key here
#** Create an account & create your API key => <your-own-scopus-api-key>
#** https://dev.elsevier.com/user/login
#** Replace the next line with set_api_key("YOUR_SCOPUS_KEY_HERE")
#** EDIT THE FOLLOWING LINE with YOUR OWN Scopus API key
#install.packages("rscopus", dependencies = TRUE)
library("rscopus")
set_api_key("5cd1321fa87640a65e146086a5cffa2b")
source("FunctionsStackOverflowApi.R")
#For example
query_string = "[devops]"#2208 items works for demo
my_filename = "devops_so"
my_articles = get_stackoverflow_data(query_string)
#install.packages("rJava", dependencies = TRUE)
library(rJava)
#remove source code and othe stuff from the body of the asnwer. It is called abstract to make it compatible with Scopus data
abstract = my_articles$Abstract
abstract = gsub("<code.*/code>", "", abstract)
abstract = gsub("<code.*<truncated>", "", abstract)
abstract = gsub("<.*?>", "", abstract)
abstract = gsub("//.*\n", " ", abstract)
abstract = gsub("\\{\n.*\\}\n", " ", abstract)
abstract = gsub("[\r\n]", " ", abstract)
abstract = gsub("\"", "", abstract)
abstract = gsub("[0-9]", "", abstract)
#Add cleaned abstracts as a new column.
#We could also replace the existing but debugging is easier if we keep both.
my_articles$Abstract_clean = tolower(abstract)
my_articles$Title = tolower(my_articles$Title)
#Date is character covert to Date object
my_articles$Date = as.Date(my_articles$Date)
my_articles$CR_Date = as.Date(my_articles$CR_Date)
my_articles$LA_Date = as.Date(my_articles$LA_Date)
#Fixed filename: data/my_STO_<xxx>_data.RData
my_file = my_work_dir
my_file = paste(my_file, "/data/my_STO_", sep="", collapse=" ")
my_file = paste(my_file, my_filename, sep="", collapse=" ")
my_file = paste(my_file, "_data.RData", sep="", collapse=" ")
save(my_articles, file=my_file)
return(my_file)
#install.packages("rJava", dependencies = TRUE)
library(rJava)
source("FunctionsTwitterApi.R")
#For example
query_string = "#DevOps"
my_filename = "devops"
#This may take quite a long time, depending on the data
#You may test duration like this. Then compute how long it would take to get max tweets
#system.time(my_articles <- get_twitter_data(query_string, maxtweets=100))
#system.time(my_articles <- get_twitter_data(query_string, maxtweets=200))
my_articles <- get_twitter_data(query_string, maxtweets=6000)
#save(my_articles, file="data/my_Twitter_articles_dirty.RData")
if (is.factor(my_articles$Abstract))
my_articles$Abstract = levels(my_articles$Abstract)[my_articles$Abstract]
abstract = my_articles$Abstract
title <- my_articles$Title
#Hashtags
abstract = gsub("#", " ", abstract)
abstract = gsub("(http|https)[://][^ ]*", " ", abstract)
abstract = gsub("@.*? ", " ", abstract)
abstract = gsub("@.*", " ", abstract)
abstract = gsub("[[:punct:]]", " ", abstract)
abstract = gsub("[\'\"/.,-:;!=%~*]", " ", abstract)
abstract = gsub("[.]", " ", abstract)
abstract = gsub("[ \t]{2,}", " ", abstract)
abstract <- chartr("åäáàâãöóòôõúùûüéèíìïëêñý", "aaaaaaooooouuuueeiiieeny", abstract)
#Text
title = gsub("#", " ", title)
title = gsub("(http|https)[://][^ ]*"," ",title)
title = gsub("@.*? ", " ", title)
title = gsub("@.*", " ", title)
title = gsub("[[:punct:]]", " ", title)
title = gsub("[\'\"/.,-:;!=%~*]", " ", title)
title = gsub("[.]", " ", title)
title = gsub("[ \t]{2,}", " ", title)
title <- chartr("åäáàâãöóòôõúùûüéèíìïëêñý", "aaaaaaooooouuuueeiiieeny", title)
if (is.factor(my_articles$AuthorName))
my_articles$AuthorName = levels(my_articles$AuthorName)[my_articles$AuthorName]
if (is.factor(my_articles$Cites)) {
my_articles$Cites = levels(my_articles$Cites)[my_articles$Cites]
my_articles$Cites = as.numeric(my_articles$Cites)
my_articles$Cites[is.na(my_articles$Cites)] = 0
}
if (is.factor(my_articles$Id)){
my_articles$Id = levels(my_articles$Id)[my_articles$Id]
my_articles$Id = as.numeric(my_articles$Id)
my_articles$Id[is.na(my_articles$Id)] = 0
}
#Add cleaned abstracts as a new column.
#We could also replace the existing but debugging is easier if we keep both.
my_articles$Abstract_clean = tolower(abstract)
my_articles$Title = tolower(title)
#Date is character covert to Date objec
my_articles$Date = as.Date(my_articles$Date)
#Fixed filename: /data/my_twitter_<xxx>_data.RData
my_file = my_work_dir
my_file = paste(my_file, "/data/my_twitter_", sep="", collapse=" ")
my_file = paste(my_file, my_filename, sep="", collapse=" ")
my_file = paste(my_file, "_data.RData", sep="", collapse=" ")
save(my_articles, file=my_file)
View(my_articles)
#For example
query_string = "#devops"
my_filename = "devops"
#This may take quite a long time, depending on the data
#You may test duration like this. Then compute how long it would take to get max tweets
#system.time(my_articles <- get_twitter_data(query_string, maxtweets=100))
#system.time(my_articles <- get_twitter_data(query_string, maxtweets=200))
my_articles <- get_twitter_data(query_string, maxtweets=6000)
View(my_articles)
View(my_articles)
#install.packages("rJava", dependencies = TRUE)
library(rJava)
source("FunctionsTwitterApi.R")
#For example
query_string = "#devops"
#For example
query_string = "#devops"
my_filename = "devops"
#This may take quite a long time, depending on the data
#You may test duration like this. Then compute how long it would take to get max tweets
#system.time(my_articles <- get_twitter_data(query_string, maxtweets=100))
#system.time(my_articles <- get_twitter_data(query_string, maxtweets=200))
my_articles <- get_twitter_data(query_string, maxtweets=6000)
View(my_articles)
#install.packages("rJava", dependencies = TRUE)
library(rJava)
source("FunctionsTwitterApi.R")
#For example
query_string = "#devops"
my_filename = "devops"
#This may take quite a long time, depending on the data
#You may test duration like this. Then compute how long it would take to get max tweets
#system.time(my_articles <- get_twitter_data(query_string, maxtweets=100))
#system.time(my_articles <- get_twitter_data(query_string, maxtweets=200))
my_articles <- get_twitter_data(query_string, maxtweets=6000)
View(my_articles)
source("FunctionsStackOverflowApi.R")
#For example
query_string = "[devops]"#2208 items works for demo
source("FunctionsStackOverflowApi.R")
setwd("E:/TrendMining/source_code/TrendMining")
source("FunctionsStackOverflowApi.R")
source("FunctionsStackOverflowApi.R")
#For example
query_string = "[devops]"#2208 items works for demo
my_filename = "devops_so"
my_articles = get_stackoverflow_data(query_string)
View(my_articles)
#remove source code and othe stuff from the body of the asnwer. It is called abstract to make it compatible with Scopus data
abstract = my_articles$Abstract
abstract = gsub("<code.*/code>", "", abstract)
abstract = gsub("<code.*<truncated>", "", abstract)
abstract = gsub("<.*?>", "", abstract)
abstract = gsub("//.*\n", " ", abstract)
abstract = gsub("\\{\n.*\\}\n", " ", abstract)
abstract = gsub("[\r\n]", " ", abstract)
abstract = gsub("\"", "", abstract)
abstract = gsub("[0-9]", "", abstract)
#Add cleaned abstracts as a new column.
#We could also replace the existing but debugging is easier if we keep both.
my_articles$Abstract_clean = tolower(abstract)
my_articles$Title = tolower(my_articles$Title)
#Date is character covert to Date object
my_articles$Date = as.Date(my_articles$Date)
my_articles$CR_Date = as.Date(my_articles$CR_Date)
my_articles$LA_Date = as.Date(my_articles$LA_Date)
#Fixed filename: data/my_STO_<xxx>_data.RData
my_file = my_work_dir
my_file = paste(my_file, "/data/my_STO_", sep="", collapse=" ")
my_file = paste(my_file, my_filename, sep="", collapse=" ")
my_file = paste(my_file, "_data.RData", sep="", collapse=" ")
save(my_articles, file=my_file)
return(my_file)
#install.packages("rJava", dependencies = TRUE)
library(rJava)
source("FunctionsTwitterApi.R")
#For example
query_string = "#devops"
my_filename = "devops"
#This may take quite a long time, depending on the data
#You may test duration like this. Then compute how long it would take to get max tweets
#system.time(my_articles <- get_twitter_data(query_string, maxtweets=100))
#system.time(my_articles <- get_twitter_data(query_string, maxtweets=200))
my_articles <- get_twitter_data(query_string, maxtweets=6000)
View(my_articles)
#install.packages("rJava", dependencies = TRUE)
library(rJava)
source("FunctionsTwitterApi.R")
#For example
query_string = "#devops"
my_filename = "devops"
#This may take quite a long time, depending on the data
#You may test duration like this. Then compute how long it would take to get max tweets
#system.time(my_articles <- get_twitter_data(query_string, maxtweets=100))
#system.time(my_articles <- get_twitter_data(query_string, maxtweets=200))
my_articles <- get_twitter_data(query_string, maxtweets=6000)
View(my_articles)
#For example
query_string = "devops"
my_filename = "devops"
#This may take quite a long time, depending on the data
#You may test duration like this. Then compute how long it would take to get max tweets
#system.time(my_articles <- get_twitter_data(query_string, maxtweets=100))
#system.time(my_articles <- get_twitter_data(query_string, maxtweets=200))
my_articles <- get_twitter_data(query_string, maxtweets=6000)
View(my_articles)
#install.packages("rJava", dependencies = TRUE)
library(rJava)
source("FunctionsTwitterApi.R")
#For example
query_string = "devops"
setwd("E:/TrendMining/source_code/TrendMining")
#install.packages("rJava", dependencies = TRUE)
library(rJava)
source("FunctionsTwitterApi.R")
#For example
query_string = "devops"
my_filename = "devops"
#This may take quite a long time, depending on the data
#You may test duration like this. Then compute how long it would take to get max tweets
#system.time(my_articles <- get_twitter_data(query_string, maxtweets=100))
#system.time(my_articles <- get_twitter_data(query_string, maxtweets=200))
my_articles <- get_twitter_data(query_string, maxtweets=6000)
#install.packages("rJava", dependencies = TRUE)
library(rJava)
source("FunctionsTwitterApi.R")
setwd("E:/TrendMining/source_code/TrendMining")
#install.packages("rJava", dependencies = TRUE)
library(rJava)
source("FunctionsTwitterApi.R")
#For example
query_string = "#devops"
my_filename = "devops"
#For example
query_string = "devops"
my_filename = "devops"
#This may take quite a long time, depending on the data
#You may test duration like this. Then compute how long it would take to get max tweets
#system.time(my_articles <- get_twitter_data(query_string, maxtweets=100))
#system.time(my_articles <- get_twitter_data(query_string, maxtweets=200))
my_articles <- get_twitter_data(query_string, maxtweets=6000)
#install.packages("rJava", dependencies = TRUE)
library(rJava)
source("FunctionsTwitterApi.R")
#For example
query_string = "#devops"
setwd("E:/TrendMining/source_code/TrendMining")
#install.packages("rJava", dependencies = TRUE)
library(rJava)
source("FunctionsTwitterApi.R")
#For example
query_string = "#devops"
my_filename = "devops"
#This may take quite a long time, depending on the data
#You may test duration like this. Then compute how long it would take to get max tweets
#system.time(my_articles <- get_twitter_data(query_string, maxtweets=100))
#system.time(my_articles <- get_twitter_data(query_string, maxtweets=200))
my_articles <- get_twitter_data(query_string, maxtweets=6000)
setwd("E:/TrendMining/source_code/TrendMining")
#install.packages("rJava", dependencies = TRUE)
library(rJava)
source("FunctionsTwitterApi.R")
#For example
query_string = "#devops"
my_filename = "devops"
#This may take quite a long time, depending on the data
#You may test duration like this. Then compute how long it would take to get max tweets
#system.time(my_articles <- get_twitter_data(query_string, maxtweets=100))
#system.time(my_articles <- get_twitter_data(query_string, maxtweets=200))
my_articles <- get_twitter_data(query_string, maxtweets=6000)
setwd("E:/TrendMining/source_code/TrendMining")
#install.packages("rJava", dependencies = TRUE)
library(rJava)
source("FunctionsTwitterApi.R")
#For example
query_string = "#devops"
my_filename = "devops"
#This may take quite a long time, depending on the data
#You may test duration like this. Then compute how long it would take to get max tweets
#system.time(my_articles <- get_twitter_data(query_string, maxtweets=100))
#system.time(my_articles <- get_twitter_data(query_string, maxtweets=200))
my_articles <- get_twitter_data(query_string, maxtweets=6000)
#** CLEAN YOUR ENVIRONMENT
#** You may want to clear your environment variables when starting a session. Saves from plenty of headache.
rm(list=ls())
#** Set your work directory to the TrendMining project directory (where the script file are)
#** A folder "data" will be created for saving files (if such folder does not exist)
#** EDIT THE FOLLOWING LINE, set your own work directory
#setwd("K:/My Documents/Projects/TrendMining_2017/TrendMining")
setwd("E:/TrendMining/source_code/TrendMining")
my_work_dir = getwd()
my_data_dir = "data"
if (!file.exists(my_data_dir)) {
dir.create(file.path(my_work_dir, my_data_dir))
}
#** STACKOVERFLOW API KEY
#** Set your own StackOverflow API key here (or use the default below)
#** EDIT THE FOLLOWING LINE for your own API key
#api_key = "9raZ36FkYGFHDSNrW)gdsw((" TODO old file name edit out
so_api_key = "Zt5gfc9eSaW68FsAKjHXhg(("
#** GETOLDTWEETS-JAVA PATH
#** Set path to the directory for "GetOldTweets-java-master"
getoldtweets_path = paste(getwd(),"/GetOldTweets-java-master", sep="")
#** SCOPUS API KEY
#** Set your own Scopus API key here
#** Create an account & create your API key => <your-own-scopus-api-key>
#** https://dev.elsevier.com/user/login
#** Replace the next line with set_api_key("YOUR_SCOPUS_KEY_HERE")
#** EDIT THE FOLLOWING LINE with YOUR OWN Scopus API key
#install.packages("rscopus", dependencies = TRUE)
library("rscopus")
set_api_key("5cd1321fa87640a65e146086a5cffa2b")
#alternatively you may store it a personal file somewhere else.
#install.packages("rJava", dependencies = TRUE)
library(rJava)
source("FunctionsTwitterApi.R")
#For example
query_string = "#devops"
my_filename = "devops"
#This may take quite a long time, depending on the data
#You may test duration like this. Then compute how long it would take to get max tweets
#system.time(my_articles <- get_twitter_data(query_string, maxtweets=100))
#system.time(my_articles <- get_twitter_data(query_string, maxtweets=200))
my_articles <- get_twitter_data(query_string, maxtweets=6000)
View(my_articles)
#save(my_articles, file="data/my_Twitter_articles_dirty.RData")
if (is.factor(my_articles$Abstract))
my_articles$Abstract = levels(my_articles$Abstract)[my_articles$Abstract]
abstract = my_articles$Abstract
title <- my_articles$Title
#Hashtags
abstract = gsub("#", " ", abstract)
abstract = gsub("(http|https)[://][^ ]*", " ", abstract)
abstract = gsub("@.*? ", " ", abstract)
abstract = gsub("@.*", " ", abstract)
abstract = gsub("[[:punct:]]", " ", abstract)
abstract = gsub("[\'\"/.,-:;!=%~*]", " ", abstract)
abstract = gsub("[.]", " ", abstract)
abstract = gsub("[ \t]{2,}", " ", abstract)
abstract <- chartr("åäáàâãöóòôõúùûüéèíìïëêñý", "aaaaaaooooouuuueeiiieeny", abstract)
#Text
title = gsub("#", " ", title)
title = gsub("(http|https)[://][^ ]*"," ",title)
title = gsub("@.*? ", " ", title)
title = gsub("@.*", " ", title)
title = gsub("[[:punct:]]", " ", title)
title = gsub("[\'\"/.,-:;!=%~*]", " ", title)
title = gsub("[.]", " ", title)
title = gsub("[ \t]{2,}", " ", title)
title <- chartr("åäáàâãöóòôõúùûüéèíìïëêñý", "aaaaaaooooouuuueeiiieeny", title)
if (is.factor(my_articles$AuthorName))
my_articles$AuthorName = levels(my_articles$AuthorName)[my_articles$AuthorName]
if (is.factor(my_articles$Cites)) {
my_articles$Cites = levels(my_articles$Cites)[my_articles$Cites]
my_articles$Cites = as.numeric(my_articles$Cites)
my_articles$Cites[is.na(my_articles$Cites)] = 0
}
if (is.factor(my_articles$Id)){
my_articles$Id = levels(my_articles$Id)[my_articles$Id]
my_articles$Id = as.numeric(my_articles$Id)
my_articles$Id[is.na(my_articles$Id)] = 0
}
#Add cleaned abstracts as a new column.
#We could also replace the existing but debugging is easier if we keep both.
my_articles$Abstract_clean = tolower(abstract)
my_articles$Title = tolower(title)
#Date is character covert to Date objec
my_articles$Date = as.Date(my_articles$Date)
#Fixed filename: /data/my_twitter_<xxx>_data.RData
my_file = my_work_dir
my_file = paste(my_file, "/data/my_twitter_", sep="", collapse=" ")
my_file = paste(my_file, my_filename, sep="", collapse=" ")
my_file = paste(my_file, "_data.RData", sep="", collapse=" ")
save(my_articles, file=my_file)
