setwd("E:/TrendMining/source_code/TrendMining")
#** CLEAN YOUR ENVIRONMENT
#** You may want to clear your environment variables when starting a session. Saves from plenty of headache.
rm(list=ls())
#** Set your work directory to the TrendMining project directory (where the script file are)
#** A folder "data" will be created for saving files (if such folder does not exist)
#** EDIT THE FOLLOWING LINE, set your own work directory
#setwd("K:/My Documents/Projects/TrendMining_2017/TrendMining")
setwd("E:/TrendMining/source_code/TrendMining")
my_work_dir = getwd()
my_data_dir = "data"
if (!file.exists(my_data_dir)) {
dir.create(file.path(my_work_dir, my_data_dir))
}
#** STACKOVERFLOW API KEY
#** Set your own StackOverflow API key here (or use the default below)
#** EDIT THE FOLLOWING LINE for your own API key
#api_key = "9raZ36FkYGFHDSNrW)gdsw((" TODO old file name edit out
so_api_key = "Zt5gfc9eSaW68FsAKjHXhg(("
#** GETOLDTWEETS-JAVA PATH
#** Set path to the directory for "GetOldTweets-java-master"
getoldtweets_path = paste(getwd(),"/GetOldTweets-java-master", sep="")
#** SCOPUS API KEY
#** Set your own Scopus API key here
#** Create an account & create your API key => <your-own-scopus-api-key>
#** https://dev.elsevier.com/user/login
#** Replace the next line with set_api_key("YOUR_SCOPUS_KEY_HERE")
#** EDIT THE FOLLOWING LINE with YOUR OWN Scopus API key
#install.packages("rscopus", dependencies = TRUE)
library("rscopus")
set_api_key("5cd1321fa87640a65e146086a5cffa2b")
#alternatively you may store it a personal file somewhere else.
#install.packages("text2vec", dependencies = TRUE)
library("text2vec")
source("FunctionsScopusApi.R")
#For example
#Finds 321 papers (29 April 2018). Suitable for classroom demo
query_string = 'DevOps'
#For example
#Finds 321 papers (29 April 2018). Suitable for classroom demo
query_string = 'TITLE-ABS-KEY ( "DevOps" )  AND  ALL ( "software" )  AND  ( LIMIT-TO ( SUBJAREA ,  "COMP" )  OR  LIMIT-TO ( SUBJAREA ,  "ENGI" ) )'
my_filename = "devops"
my_query_string = "TITLE-ABS-KEY(\""
#For example
#Finds 321 papers (29 April 2018). Suitable for classroom demo
query_string = 'DevOps'
my_filename = "devops"
my_query_string = "TITLE-ABS-KEY(\""
my_query_string = paste(my_query_string, query_string, sep="")
#EDIT this line
my_query_string = paste(my_query_string, "\") AND  ALL ( \"software\" )  AND  ( LIMIT-TO ( SUBJAREA ,  \"COMP\" )  OR  LIMIT-TO ( SUBJAREA ,  \"ENGI\" ) )", sep="")
#Get articles and save those - we do not want to re-run the query
my_articles = get_scopus_papers(my_query_string)
library(jsonlite)
#install.packages("text2vec", dependencies = TRUE)
library("text2vec")
source("FunctionsScopusApi.R")
#For example
#Finds 321 papers (29 April 2018). Suitable for classroom demo
query_string = 'DevOps'
my_filename = "devops"
my_query_string = "TITLE-ABS-KEY(\""
my_query_string = paste(my_query_string, query_string, sep="")
#EDIT this line
my_query_string = paste(my_query_string, "\") AND  ALL ( \"software\" )  AND  ( LIMIT-TO ( SUBJAREA ,  \"COMP\" )  OR  LIMIT-TO ( SUBJAREA ,  \"ENGI\" ) )", sep="")
#Get articles and save those - we do not want to re-run the query
my_articles = get_scopus_papers(my_query_string)
#Get articles and save those - we do not want to re-run the query
my_articles = get_scopus_papers(my_query_string)
source("FunctionsScopusApi.R")
#For example
#Finds 321 papers (29 April 2018). Suitable for classroom demo
query_string = 'DevOps'
my_filename = "devops"
my_query_string = "TITLE-ABS-KEY(\""
my_query_string = paste(my_query_string, query_string, sep="")
#EDIT this line
my_query_string = paste(my_query_string, "\") AND  ALL ( \"software\" )  AND  ( LIMIT-TO ( SUBJAREA ,  \"COMP\" )  OR  LIMIT-TO ( SUBJAREA ,  \"ENGI\" ) )", sep="")
#Get articles and save those - we do not want to re-run the query
my_articles = get_scopus_papers(my_query_string)
View(get_scopus_papers)
#http://api.elsevier.com/documentation/search/SCOPUSSearchViews.htm
#https://api.elsevier.com/documentation/SCOPUSSearchAPI.wadl
#https://dev.elsevier.com/guides/ScopusSearchViews.htm
#Scopus response https://dev.elsevier.com/payloads/search/scopusSearchResp.json
#resp = generic_elsevier_api(query=query_string, type="search", search_type="scopus", cursor=cursor_value, view="COMPLETE")
resp = read_json("scopus.json")
View(resp)
#http://api.elsevier.com/documentation/search/SCOPUSSearchViews.htm
#https://api.elsevier.com/documentation/SCOPUSSearchAPI.wadl
#https://dev.elsevier.com/guides/ScopusSearchViews.htm
#Scopus response https://dev.elsevier.com/payloads/search/scopusSearchResp.json
#resp = generic_elsevier_api(query=query_string, type="search", search_type="scopus", cursor=cursor_value, view="COMPLETE")
resp$content = read_json("scopus.json")
View(resp)
source("FunctionsScopusApi.R")
#For example
#Finds 321 papers (29 April 2018). Suitable for classroom demo
query_string = 'DevOps'
my_filename = "devops"
my_query_string = "TITLE-ABS-KEY(\""
my_query_string = paste(my_query_string, query_string, sep="")
#EDIT this line
my_query_string = paste(my_query_string, "\") AND  ALL ( \"software\" )  AND  ( LIMIT-TO ( SUBJAREA ,  \"COMP\" )  OR  LIMIT-TO ( SUBJAREA ,  \"ENGI\" ) )", sep="")
#Get articles and save those - we do not want to re-run the query
my_articles = get_scopus_papers(my_query_string)
View(my_articles)
#Remove copyright sign.
abstract = my_articles$Abstract
abstract = gsub("Copyright ?+[^.]*[.]","",abstract)
abstract = gsub("?+[^.]*[.]","",abstract) # Depdenging on the enviroment or data you might need something different*
abstract = gsub("All rights reserved[.]","",abstract)
abstract = gsub("All right reserved[.]","",abstract)
abstract = gsub("No abstract available[.]","",abstract)
abstract = gsub("[0-9]", "", abstract)
#It is easy to accidentally too much or too little.
#Check length of abstracts -> ratio of new vs origal
nchar(abstract)/nchar(my_articles$Abstract)
mean (nchar(abstract)/nchar(my_articles$Abstract), na.rm=TRUE)
abstract[nchar(abstract)/nchar(my_articles$Abstract)<0.5]
#Add cleaned abstracts as a NEW column.
#We could also replace the existing but debugging is easier if we keep both.
my_articles$Abstract_clean = tolower(abstract)
my_articles$Title = tolower(my_articles$Title)
#Remove papers that are summaries of conference proceedings.
#If check needed otherwise 0 would remove all papers.
if (length(grep("proceedings contain", my_articles$Abstract_clean, ignore.case = TRUE)) > 0){
my_articles = my_articles[-grep("proceedings contain", my_articles$Abstract_clean, ignore.case = TRUE),]
}
#Date is character convert to Date object
my_articles$Date = as.Date(my_articles$Date)
#Fixed filename: /data/my_scopus_<my_filename>_data.RData
my_file = my_work_dir
my_file = paste(my_file, "/data/my_Scopus_", sep="", collapse=" ")
my_file = paste(my_file, my_filename, sep="", collapse=" ")
my_file = paste(my_file, "_data.RData", sep="", collapse=" ")
save(my_articles, file=my_file)
View(my_articles)
#Get articles and save those - we do not want to re-run the query
my_articles = get_scopus_papers(my_query_string)
#Remove copyright sign.
abstract = my_articles$Abstract
abstract = gsub("Copyright ©+[^.]*[.]","",abstract)
abstract = gsub("©+[^.]*[.]","",abstract) # Depdenging on the enviroment or data you might need something different*
abstract = gsub("All rights reserved[.]","",abstract)
abstract = gsub("All right reserved[.]","",abstract)
abstract = gsub("No abstract available[.]","",abstract)
abstract = gsub("[0-9]", "", abstract)
#It is easy to accidentally too much or too little.
#Check length of abstracts -> ratio of new vs origal
nchar(abstract)/nchar(my_articles$Abstract)
mean (nchar(abstract)/nchar(my_articles$Abstract), na.rm=TRUE)
abstract[nchar(abstract)/nchar(my_articles$Abstract)<0.5]
#Add cleaned abstracts as a NEW column.
#We could also replace the existing but debugging is easier if we keep both.
my_articles$Abstract_clean = tolower(abstract)
my_articles$Title = tolower(my_articles$Title)
#Remove papers that are summaries of conference proceedings.
#If check needed otherwise 0 would remove all papers.
if (length(grep("proceedings contain", my_articles$Abstract_clean, ignore.case = TRUE)) > 0){
my_articles = my_articles[-grep("proceedings contain", my_articles$Abstract_clean, ignore.case = TRUE),]
}
#Date is character convert to Date object
my_articles$Date = as.Date(my_articles$Date)
#Fixed filename: /data/my_scopus_<my_filename>_data.RData
my_file = my_work_dir
my_file = paste(my_file, "/data/my_Scopus_", sep="", collapse=" ")
my_file = paste(my_file, my_filename, sep="", collapse=" ")
my_file = paste(my_file, "_data.RData", sep="", collapse=" ")
save(my_articles, file=my_file)
View(my_articles)
